{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Vehicle Detection and Tracking: Challenge\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import glob\n",
    "import matplotlib.pyplot as plt\n",
    "from skimage import io\n",
    "%matplotlib inline\n",
    "import pickle\n",
    "\n",
    "from aux_fun import *\n",
    "from p4_fun import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training parameters definition:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "PARAMS = {\n",
    "    'use_spatial': True,\n",
    "    'spatial_cspace': 'YCrCb',\n",
    "    'spatial_resize': 32,\n",
    "    \n",
    "    'use_hist': True,\n",
    "    'hist_cspace': 'YCrCb',\n",
    "    'hist_nbins': 32,\n",
    "    \n",
    "    'use_hog': True,\n",
    "    'hog_cspace': 'YCrCb',\n",
    "    'channels_for_hog': [0,1,2],\n",
    "    'hog_orientations': 9,\n",
    "    'hog_pixels_per_cell': 16,\n",
    "    'hog_cells_per_block': 2,\n",
    "    \n",
    "    'cells_per_step_overlap': 1\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building the training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "car_image_fnames = glob.glob('data/vehicles/*/*.png')\n",
    "not_car_image_fnames = glob.glob('data/non-vehicles/*/*.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset size:  (17760, 4140)\n"
     ]
    }
   ],
   "source": [
    "X, y = build_dataset(\n",
    "    car_image_fnames, not_car_image_fnames, \n",
    "    hog_orientations=PARAMS['hog_orientations'], \n",
    "    hog_pixels_per_cell=PARAMS['hog_pixels_per_cell'], \n",
    "    hog_cells_per_block=PARAMS['hog_cells_per_block'],\n",
    "    hist_nbins=PARAMS['hist_nbins'],\n",
    "    spatial_resize=PARAMS['spatial_resize'],\n",
    "    channels_for_hog=PARAMS['channels_for_hog'],\n",
    "    use_hog=PARAMS['use_hog'],\n",
    "    hog_cspace=PARAMS['hog_cspace'],\n",
    "    use_spatial=PARAMS['use_spatial'],\n",
    "    spatial_cspace=PARAMS['spatial_cspace'],\n",
    "    use_hist=PARAMS['use_hist'],\n",
    "    hist_cspace=PARAMS['hist_cspace']\n",
    ")\n",
    "print('Dataset size: ', X.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaled_clf = make_pipeline(\n",
    "    StandardScaler(),\n",
    "    LinearSVC(\n",
    "        C=10\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('standardscaler', StandardScaler(copy=True, with_mean=True, with_std=True)), ('linearsvc', LinearSVC(C=10, class_weight=None, dual=True, fit_intercept=True,\n",
       "     intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
       "     multi_class='ovr', penalty='l2', random_state=None, tol=0.0001,\n",
       "     verbose=0))])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaled_clf.fit(X,y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lane pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Line():\n",
    "    def __init__(self):\n",
    "        self.previous_fit_coeffs = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def lane_detection_pl(original_img_rgb, thr_pipeline, l_lane, r_lane, \n",
    "                      camera_params, src_vertices, dst_vertices):\n",
    "    \n",
    "    undist_img = undistort(original_img_rgb, camera_params)\n",
    "    binary_img = thr_pipeline(undist_img)\n",
    "    binary_warped = warp_image(binary_img, src_vertices, dst_vertices)\n",
    "    \n",
    "    if (l_lane.previous_fit_coeffs is None) or (l_lane.previous_fit_coeffs is None):\n",
    "        leftx, lefty, rightx, righty, _ = find_lanes_sliding_window_hist(binary_warped, get_viz=False)\n",
    "    else:\n",
    "        leftx, lefty, rightx, righty, _ = find_lanes_near_previous(\n",
    "            binary_warped,\n",
    "            l_lane.previous_fit_coeffs,\n",
    "            r_lane.previous_fit_coeffs,\n",
    "            get_viz=False)\n",
    "        \n",
    "    left_fit, right_fit = get_lane_fit_coeffs(leftx, lefty, rightx, righty)\n",
    "    l_lane.previous_fit_coeffs = left_fit\n",
    "    r_lane.previous_fit_coeffs = right_fit\n",
    "    \n",
    "    y_eval = binary_warped.shape[0]\n",
    "    r_left = calculate_radius_in_meters(y_eval, left_fit, 3.7/700, 30/720)\n",
    "    r_right = calculate_radius_in_meters(y_eval, right_fit, 3.7/700, 30/720)\n",
    "    \n",
    "    offset = calculate_offset_in_meters(binary_warped, left_fit, right_fit, 3.7/700)\n",
    "    \n",
    "    ploty = np.linspace(0, binary_warped.shape[0]-1, binary_warped.shape[0])\n",
    "    left_fitx = left_fit[0]*ploty**2 + left_fit[1]*ploty + left_fit[2]\n",
    "    right_fitx = right_fit[0]*ploty**2 + right_fit[1]*ploty + right_fit[2]\n",
    "    \n",
    "    res = print_summary_on_original_image(\n",
    "        undist_img, binary_warped,\n",
    "        left_fitx, right_fitx, ploty,\n",
    "        leftx, lefty, rightx, righty,\n",
    "        r_left, r_right, offset,\n",
    "        src_vertices, dst_vertices\n",
    "    )\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "camera_params = pickle.load(open('challenge/camera_params.p', 'rb'))\n",
    "src_vertices = pickle.load(open('challenge/src_vertices.p', 'rb'))\n",
    "dst_vertices = pickle.load(open('challenge/dst_vertices.p', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lane_process = lambda img, l_lane, r_lane: lane_detection_pl(\n",
    "    img, thresholding_pipeline, l_lane, r_lane, camera_params, src_vertices, dst_vertices\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prediction pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# wrapper for the find_cars() method to be easier to use\n",
    "detect_for_scale = lambda img, ystart, ystop, scale: find_cars(\n",
    "    img, \n",
    "    ystart=ystart, ystop=ystop, \n",
    "    scale=scale,\n",
    "    cells_per_step_overlap=PARAMS['cells_per_step_overlap'],\n",
    "    clf_pl=scaled_clf, \n",
    "    use_hog=PARAMS['use_hog'], hog_cspace=PARAMS['hog_cspace'], \n",
    "    channels_for_hog=PARAMS['channels_for_hog'],\n",
    "    orient=PARAMS['hog_orientations'], \n",
    "    pix_per_cell=PARAMS['hog_pixels_per_cell'], \n",
    "    cell_per_block=PARAMS['hog_cells_per_block'],\n",
    "    use_spatial=PARAMS['use_spatial'], spatial_cspace=PARAMS['spatial_cspace'], \n",
    "    spatial_size=PARAMS['spatial_resize'], \n",
    "    use_hist=PARAMS['use_hist'], hist_cspace=PARAMS['hist_cspace'], \n",
    "    hist_bins=PARAMS['hist_nbins']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from scipy.ndimage.measurements import label\n",
    "class VehicleTracker:\n",
    "    def __init__(self, frame_size, new_frame_factor=0.5, heatmap_threshold=2):\n",
    "        self.new_frame_factor = new_frame_factor\n",
    "        self.heatmap_threshold = heatmap_threshold\n",
    "        self.heatmap = np.zeros(frame_size)\n",
    "        self.l_lane = Line()\n",
    "        self.r_lane = Line()\n",
    "        \n",
    "    def process_frame(self, frame):\n",
    "        \n",
    "        # search for detections over different scaled windows and store the \n",
    "        # positive bounding boxes in the hot_windows list\n",
    "        hot_windows = list()\n",
    "        hot_windows += detect_for_scale(frame, ystart=400, ystop=500, scale=1.0)\n",
    "        hot_windows += detect_for_scale(frame, ystart=400, ystop=600, scale=2.0)\n",
    "        hot_windows += detect_for_scale(frame, ystart=400, ystop=650, scale=3.0)\n",
    "        \n",
    "        # build heatmap based on the multi-scale detections\n",
    "        frame_heat = np.zeros_like(frame[:,:,0]).astype(np.float)\n",
    "        frame_heat = add_heat(frame_heat, hot_windows)\n",
    "        \n",
    "        # apply weighted average between the current heatmap and the averaged over the \n",
    "        # previous steps\n",
    "        self.heatmap = self.new_frame_factor * frame_heat + (1 - self.new_frame_factor) * self.heatmap\n",
    "        \n",
    "        # threshold the resulting heatmap to highlight high-confidence detections\n",
    "        thresholded_heatmap = apply_threshold(self.heatmap, threshold=self.heatmap_threshold)\n",
    "        \n",
    "        # define tight bounding boxes for the high-confidence detections\n",
    "        labels = label(thresholded_heatmap)\n",
    "        \n",
    "        # print lane information\n",
    "        annotated_lane_img = lane_process(frame, self.l_lane, self.r_lane)\n",
    "        \n",
    "        # draw the boxes \n",
    "        proccessed_frame = draw_labeled_bboxes(annotated_lane_img, labels)\n",
    "        \n",
    "        return proccessed_frame"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Video generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from moviepy.editor import VideoFileClip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[MoviePy] >>>> Building video challenge/challenge_solution.mp4\n",
      "[MoviePy] Writing video challenge/challenge_solution.mp4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████▉| 1260/1261 [06:18<00:00,  3.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[MoviePy] Done.\n",
      "[MoviePy] >>>> Video ready: challenge/challenge_solution.mp4 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "build_video = True\n",
    "if build_video:\n",
    "    vehicleTracker = VehicleTracker(\n",
    "        frame_size=(720, 1280), \n",
    "        new_frame_factor=0.5, \n",
    "        heatmap_threshold=2\n",
    "    )\n",
    "    output = 'challenge/challenge_solution.mp4'\n",
    "    clip = VideoFileClip('project_video.mp4')\n",
    "    output_clip = clip.fl_image(vehicleTracker.process_frame)\n",
    "    output_clip.write_videofile(output, audio=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
